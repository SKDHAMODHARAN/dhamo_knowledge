# 04 â€” State Management ğŸ—„ï¸

> **The #1 topic that breaks teams**: Without remote state, two engineers can corrupt your infrastructure with a single `terraform apply`.

---

## The Problem with Local State

Default behavior â€” Terraform saves state on your local machine:

```
my-project/
â”œâ”€â”€ main.tf
â”œâ”€â”€ variables.tf
â””â”€â”€ terraform.tfstate   â† Saved locally. This is the problem.
```

### What Goes Wrong on a Team

```
Developer A runs terraform apply â†’ state file on A's laptop
Developer B runs terraform apply â†’ B's state is outdated
                                 â†’ B thinks VPC doesn't exist
                                 â†’ B RECREATES the VPC ğŸ’¥
                                 â†’ OR overwrites what A did ğŸ’¥
```

Or worse:

```
Developer B deletes their laptop
  â†’ State file is gone
  â†’ Terraform no longer knows what exists in AWS
  â†’ terraform plan tries to create EVERYTHING again
  â†’ Including things that already exist = errors or duplicates
```

---

## The Solution: Remote State with S3 + DynamoDB

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  S3 Bucket              â†’ Stores the state file         â”‚
â”‚  DynamoDB Table         â†’ Provides locking               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Developer A:  terraform apply
  â†’ Acquires DynamoDB lock
  â†’ Reads current state from S3
  â†’ Makes changes
  â†’ Writes updated state to S3
  â†’ Releases lock

Developer B:  terraform apply (at same time)
  â†’ Tries to acquire lock
  â†’ Lock exists! B waits (or fails fast with a clear error)
  â†’ A finishes â†’ lock released â†’ B proceeds safely
```

---

## Step 1: Bootstrap â€” Create the State Bucket and Lock Table

Create this ONCE, before any other Terraform work. Store it in a separate `bootstrap/` folder:

```hcl
# bootstrap/main.tf

provider "aws" { region = "us-east-1" }

# â”€â”€ S3 bucket to store all Terraform state â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
resource "aws_s3_bucket" "terraform_state" {
  bucket = "mycompany-terraform-state"   # Must be globally unique

  lifecycle {
    prevent_destroy = true   # Never allow accidental deletion
  }

  tags = { Name = "Terraform State", ManagedBy = "terraform" }
}

# Enable versioning so you can recover from bad state
resource "aws_s3_bucket_versioning" "state" {
  bucket = aws_s3_bucket.terraform_state.id
  versioning_configuration { status = "Enabled" }
}

# Encrypt state at rest â€” state files contain sensitive data
resource "aws_s3_bucket_server_side_encryption_configuration" "state" {
  bucket = aws_s3_bucket.terraform_state.id
  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}

# Block all public access â€” state files must NEVER be public
resource "aws_s3_bucket_public_access_block" "state" {
  bucket                  = aws_s3_bucket.terraform_state.id
  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}

# â”€â”€ DynamoDB table for distributed locking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
resource "aws_dynamodb_table" "terraform_locks" {
  name         = "mycompany-terraform-locks"
  billing_mode = "PAY_PER_REQUEST"
  hash_key     = "LockID"   # Terraform requires this exact name

  attribute {
    name = "LockID"
    type = "S"
  }

  tags = { Name = "Terraform State Locks", ManagedBy = "terraform" }
}
```

Run this FIRST:
```bash
cd bootstrap/
terraform init
terraform apply   # Creates the S3 bucket and DynamoDB table
```

---

## Step 2: Configure Backend in Your Main Projects

Every other Terraform project now uses this backend:

```hcl
# backend.tf

terraform {
  backend "s3" {
    bucket         = "mycompany-terraform-state"
    key            = "platform/vpc/terraform.tfstate"   # Path inside the bucket
    region         = "us-east-1"
    dynamodb_table = "mycompany-terraform-locks"
    encrypt        = true
  }
}
```

Reinitialize to migrate:
```bash
terraform init
# Asks: "Do you want to copy existing state to the new backend?" â†’ yes
```

---

## State Path Strategy â€” Organize State by Project + Environment

```
S3: mycompany-terraform-state/
â”œâ”€â”€ bootstrap/terraform.tfstate
â”‚
â”œâ”€â”€ platform/
â”‚   â”œâ”€â”€ vpc/dev/terraform.tfstate
â”‚   â”œâ”€â”€ vpc/staging/terraform.tfstate
â”‚   â”œâ”€â”€ vpc/prod/terraform.tfstate
â”‚   â”œâ”€â”€ eks/dev/terraform.tfstate
â”‚   â”œâ”€â”€ eks/prod/terraform.tfstate
â”‚   â””â”€â”€ rds/prod/terraform.tfstate
â”‚
â”œâ”€â”€ security/
â”‚   â”œâ”€â”€ iam/terraform.tfstate
â”‚   â””â”€â”€ guardduty/terraform.tfstate
â”‚
â””â”€â”€ applications/
    â”œâ”€â”€ api-service/dev/terraform.tfstate
    â””â”€â”€ api-service/prod/terraform.tfstate
```

---

## Cross-Module State Reference

When one module needs values from another module's state:

```hcl
# In your EKS module â€” read VPC outputs from the networking module
data "terraform_remote_state" "vpc" {
  backend = "s3"
  config = {
    bucket = "mycompany-terraform-state"
    key    = "platform/vpc/prod/terraform.tfstate"
    region = "us-east-1"
  }
}

resource "aws_eks_cluster" "main" {
  name = "platform-cluster"

  vpc_config {
    subnet_ids = data.terraform_remote_state.vpc.outputs.private_subnet_ids
  }
}
```

---

## Essential State Commands

```bash
# See everything Terraform is tracking
terraform state list

# Inspect a specific resource in state
terraform state show aws_vpc.main

# Remove from state WITHOUT deleting the resource in AWS
# Use case: you want to manage a resource differently, or move it to another config
terraform state rm aws_vpc.main

# Import an existing AWS resource into Terraform management
# Use case: someone created a VPC manually, now you want Terraform to own it
terraform import aws_vpc.main vpc-0abc1234

# Rename a resource in state (when you rename it in .tf code)
terraform state mv aws_vpc.old_name aws_vpc.new_name

# View full state as JSON
terraform show -json

# Force-unlock a stuck lock (if apply crashed mid-way)
terraform force-unlock <LOCK_ID>
```

---

## `prevent_destroy` Lifecycle Guard

Use on anything in production that should never be deleted:

```hcl
resource "aws_vpc" "main" {
  cidr_block = "10.0.0.0/16"

  lifecycle {
    prevent_destroy = true
  }
}

resource "aws_db_instance" "main" {
  # ...
  lifecycle {
    prevent_destroy       = true    # Don't delete the DB
    ignore_changes        = [password]  # Don't update if password changes outside TF
    create_before_destroy = true    # For zero-downtime replacements
  }
}
```

---

## Common State Mistakes

| Mistake | Consequence | Fix |
|---------|-------------|-----|
| Committing `terraform.tfstate` to Git | Plaintext secrets exposed | Remote state + `.gitignore` |
| Two engineers apply simultaneously | State corruption | Remote state + DynamoDB lock |
| Deleting state file | TF recreates everything | S3 versioning + backups |
| Editing `tfstate` by hand | State corruption | Use `terraform state` commands |
| Running `destroy` on prod | Infrastructure gone | `prevent_destroy` + IAM restrictions |

---

## `.gitignore` Additions for Terraform

```gitignore
# Local state (never commit)
*.tfstate
*.tfstate.*
*.tfstate.backup

# Downloaded provider plugins (re-downloaded via terraform init)
.terraform/

# Crash logs
crash.log
crash.*.log

# Commit this file â€” it locks provider versions for the team:
# .terraform.lock.hcl  â† DO commit this one

# Only ignore .tfvars if they contain secrets
*.tfvars
!example.tfvars   # Commit the example, not the real values
```

---

## âœ… Test Your Understanding

1. Why do we need both S3 AND DynamoDB â€” what does each one do?
2. A `terraform apply` fails halfway through. What is the state of the infrastructure and what do you do?
3. An engineer on your team created an EC2 instance manually in the AWS console. Your manager wants it managed by Terraform going forward. What command do you use?

> **Answers**: 1) S3 stores the actual state JSON file. DynamoDB provides distributed locking â€” prevents concurrent applies from corrupting state. 2) Partial state â€” some resources exist in AWS and are recorded in state; others failed. Run `terraform plan` to see what's missing, then `terraform apply` again to complete it. 3) `terraform import aws_instance.name <instance-id>` â€” then write the matching resource block in your .tf file.

---

**Next**: [05 â€” Modules](./05-modules.md) â†’ The most important concept for writing maintainable, reusable infrastructure code.
