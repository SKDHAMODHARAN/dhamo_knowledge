# 02 â€” Kubernetes Architecture

## The Big Picture

Think of Kubernetes like an **airline company**:

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AIRLINE COMPANY = CLUSTER                     â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    CONTROL TOWER (HQ)      â”‚    â”‚         AIRPLANES            â”‚  â”‚
â”‚  â”‚    = Control Plane         â”‚    â”‚         = Worker Nodes        â”‚  â”‚
â”‚  â”‚                            â”‚    â”‚                              â”‚  â”‚
â”‚  â”‚  â€¢ Decides which plane     â”‚    â”‚  â€¢ Actually carry the        â”‚  â”‚
â”‚  â”‚    goes where              â”‚    â”‚    passengers (your apps)    â”‚  â”‚
â”‚  â”‚  â€¢ Monitors all flights    â”‚    â”‚  â€¢ Report status back to HQ â”‚  â”‚
â”‚  â”‚  â€¢ Reschedules if a plane  â”‚    â”‚  â€¢ Follow instructions      â”‚  â”‚
â”‚  â”‚    has problems            â”‚    â”‚    from control tower        â”‚  â”‚
â”‚  â”‚  â€¢ Stores all flight data  â”‚    â”‚                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

A Kubernetes cluster has **two main parts**:
1. **Control Plane** â€” the brain (makes decisions)
2. **Worker Nodes** â€” the muscles (run your apps)

---

## Complete Architecture Diagram

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          KUBERNETES CLUSTER                                â”‚
â”‚                                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                      CONTROL PLANE (Master)                          â”‚  â”‚
â”‚  â”‚                                                                      â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  API Server   â”‚  â”‚  Scheduler   â”‚  â”‚  Controller Manager        â”‚ â”‚  â”‚
â”‚  â”‚  â”‚              â”‚  â”‚              â”‚  â”‚                            â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ Front door   â”‚  â”‚ Decides whichâ”‚  â”‚ Watches & fixes things:   â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ for ALL      â”‚  â”‚ node runs    â”‚  â”‚ â€¢ ReplicaSet controller   â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ communicationâ”‚  â”‚ each pod     â”‚  â”‚ â€¢ Deployment controller   â”‚ â”‚  â”‚
â”‚  â”‚  â”‚              â”‚  â”‚              â”‚  â”‚ â€¢ Node controller         â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ Port: 6443   â”‚  â”‚              â”‚  â”‚ â€¢ Job controller          â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚         â”‚                                                            â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚    etcd       â”‚  â”‚  Cloud Controller Manager (optional)         â”‚ â”‚  â”‚
â”‚  â”‚  â”‚              â”‚  â”‚  Talks to AWS/GCP/Azure for load balancers,  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ The database â”‚  â”‚  storage, and node management                â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ (key-value)  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚  â”‚ Stores ALL   â”‚                                                    â”‚  â”‚
â”‚  â”‚  â”‚ cluster stateâ”‚                                                    â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                    â”‚                                       â”‚
â”‚                          kubectl / API calls                               â”‚
â”‚                                    â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                        WORKER NODES                                  â”‚  â”‚
â”‚  â”‚                                                                      â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚         NODE 1              â”‚  â”‚         NODE 2              â”‚   â”‚  â”‚
â”‚  â”‚  â”‚                             â”‚  â”‚                             â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ Pod A  â”‚ â”‚ Pod B  â”‚     â”‚  â”‚  â”‚ Pod C  â”‚                â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚   â”‚  â”‚
â”‚  â”‚  â”‚                             â”‚  â”‚                             â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ kubelet             â”‚   â”‚  â”‚  â”‚ kubelet             â”‚   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ (Node agent)        â”‚   â”‚  â”‚  â”‚ (Node agent)        â”‚   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ kube-proxy          â”‚   â”‚  â”‚  â”‚ kube-proxy          â”‚   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ (Network rules)     â”‚   â”‚  â”‚  â”‚ (Network rules)     â”‚   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ Container Runtime   â”‚   â”‚  â”‚  â”‚ Container Runtime   â”‚   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ (containerd/CRI-O)  â”‚   â”‚  â”‚  â”‚ (containerd/CRI-O)  â”‚   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Control Plane Components (The Brain)

### 1. API Server (`kube-apiserver`)

```text
Think of it as: The RECEPTION DESK of a hospital

  Doctor (kubectl)  â”€â”€â†’  Reception (API Server)  â”€â”€â†’  Hospital systems
  Patient (Pod)     â”€â”€â†’  Reception (API Server)  â”€â”€â†’  Assign room
  Nurse (kubelet)   â”€â”€â†’  Reception (API Server)  â”€â”€â†’  Report status

EVERYTHING goes through reception. No one talks directly to each other.
```

| What It Does | Details |
|---|---|
| **Single entry point** | Every request (from kubectl, nodes, controllers) goes through the API Server |
| **Authentication** | Checks WHO you are (certificates, tokens) |
| **Authorization** | Checks WHAT you're allowed to do (RBAC) |
| **Validation** | Checks if your request makes sense (valid YAML?) |
| **Persists state** | Writes everything to etcd |

**Key point:** The API Server is **stateless**. It doesn't store anything itself â€” it reads/writes to etcd.

### 2. etcd

```text
Think of it as: The FILING CABINET where the hospital stores every patient record

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                     etcd                          â”‚
  â”‚                                                  â”‚
  â”‚  Key                    â”‚  Value                  â”‚
  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
  â”‚  /pods/nginx-abc123     â”‚  {status: Running...}  â”‚
  â”‚  /deployments/web       â”‚  {replicas: 3...}      â”‚
  â”‚  /services/frontend     â”‚  {port: 80...}         â”‚
  â”‚  /nodes/worker-1        â”‚  {ready: true...}      â”‚
  â”‚  /secrets/db-password   â”‚  {encoded: base64...}  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| What It Does | Details |
|---|---|
| **Stores ALL cluster state** | Every Pod, Service, Deployment, Secret â€” everything is in etcd |
| **Key-value database** | Simple storage: key â†’ value |
| **Distributed** | Runs on multiple machines for reliability |
| **Source of truth** | If it's not in etcd, Kubernetes doesn't know about it |

**Critical production rule:** Always back up etcd. Losing etcd = losing your entire cluster state.

### 3. Scheduler (`kube-scheduler`)

```text
Think of it as: A WEDDING PLANNER assigning guests to tables

  "Table 1 has space, Table 2 is full, Guest X needs wheelchair access..."

  The Scheduler decides WHICH NODE runs each new Pod:

  New Pod needs:
    - 500m CPU
    - 256Mi memory
    - GPU: yes
    - Zone: us-east-1a

  Scheduler checks:
    Node 1: 2000m CPU free, 4Gi memory, NO GPU     â†’ âŒ No GPU
    Node 2: 100m CPU free, 128Mi memory, has GPU    â†’ âŒ Not enough resources
    Node 3: 1000m CPU free, 2Gi memory, has GPU     â†’ âœ… Perfect match!

  Result: Pod â†’ Node 3
```

| Factor | What It Checks |
|--------|---------------|
| **Resource requests** | Does the node have enough CPU/memory? |
| **Node selectors** | Does the Pod require specific node labels? |
| **Taints & tolerations** | Is the node reserved for specific workloads? |
| **Affinity rules** | Should this Pod be near/far from other Pods? |
| **Available ports** | Does the node have the required ports free? |

### 4. Controller Manager (`kube-controller-manager`)

```text
Think of it as: A team of QUALITY INSPECTORS in a factory

Each inspector watches ONE thing and fixes it if it's wrong:

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                  Controller Manager                       â”‚
  â”‚                                                          â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
  â”‚  â”‚ ReplicaSet Controllerâ”‚  â”‚ Node Controller     â”‚       â”‚
  â”‚  â”‚                     â”‚  â”‚                     â”‚       â”‚
  â”‚  â”‚ "You said 3 pods,   â”‚  â”‚ "Node 2 stopped    â”‚       â”‚
  â”‚  â”‚  I see 2. Let me    â”‚  â”‚  responding. Mark   â”‚       â”‚
  â”‚  â”‚  create 1 more."    â”‚  â”‚  it as NotReady."   â”‚       â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
  â”‚                                                          â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
  â”‚  â”‚ Deployment Controllerâ”‚  â”‚ Job Controller      â”‚       â”‚
  â”‚  â”‚                     â”‚  â”‚                     â”‚       â”‚
  â”‚  â”‚ "New version? Let   â”‚  â”‚ "Run this task once â”‚       â”‚
  â”‚  â”‚  me do a rolling    â”‚  â”‚  and mark it done." â”‚       â”‚
  â”‚  â”‚  update."           â”‚  â”‚                     â”‚       â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
  â”‚                                                          â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
  â”‚  â”‚ Service Controller  â”‚  â”‚ Endpoint Controller  â”‚       â”‚
  â”‚  â”‚                     â”‚  â”‚                     â”‚       â”‚
  â”‚  â”‚ "Cloud LB needed.   â”‚  â”‚ "Update the list of â”‚       â”‚
  â”‚  â”‚  Let me create it." â”‚  â”‚  Pod IPs behind thisâ”‚       â”‚
  â”‚  â”‚                     â”‚  â”‚  Service."          â”‚       â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The key concept:** Every controller runs a **reconciliation loop**:

```text
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                                                   â”‚
  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     Compare      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
  â”‚   â”‚ DESIRED  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’  â”‚ ACTUAL   â”‚     â”‚
  â”‚   â”‚ STATE    â”‚                  â”‚ STATE    â”‚     â”‚
  â”‚   â”‚          â”‚                  â”‚          â”‚     â”‚
  â”‚   â”‚ "I want  â”‚     Different?   â”‚ "I have  â”‚     â”‚
  â”‚   â”‚  3 pods" â”‚     Take action! â”‚  2 pods" â”‚     â”‚
  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
  â”‚        â–²                             â”‚            â”‚
  â”‚        â”‚         Reconcile           â”‚            â”‚
  â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
  â”‚              (Create 1 more pod)                  â”‚
  â”‚                                                   â”‚
  â”‚   This loop runs FOREVER, every few seconds.      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

This is the **most important concept in Kubernetes**: You tell it the **desired state**, and it continuously works to make **actual state = desired state**.

---

## Worker Node Components (The Muscles)

### 1. kubelet

```text
Think of it as: A SITE MANAGER at a construction site

  Control Plane says: "Build 3 houses on this lot"
  kubelet (Site Manager):
    âœ… Starts building (pulls container images, creates containers)
    âœ… Checks every 10 seconds: "Are the houses still standing?"
    âœ… Reports back: "All 3 houses are up and running"
    âœ… If a house falls â†’ rebuilds it immediately
```

| What It Does | Details |
|---|---|
| **Runs on every node** | One kubelet per worker node |
| **Manages Pods** | Creates, starts, stops, and monitors containers |
| **Health checks** | Runs liveness/readiness probes |
| **Reports status** | Tells the API Server: "I'm healthy, here's what's running" |
| **Pulls images** | Downloads container images from registries |

### 2. kube-proxy

```text
Think of it as: A TELEPHONE SWITCHBOARD OPERATOR

  Incoming call â†’ "I want to talk to the 'web' service"
  kube-proxy   â†’ "Let me route you to one of the 3 web servers"

  It maintains network rules so that when you say
  "connect to service X", traffic reaches the right Pod.
```

| What It Does | Details |
|---|---|
| **Runs on every node** | Maintains network rules |
| **Load balancing** | Distributes traffic across Pods |
| **Service networking** | Makes Services work (maps Service IP â†’ Pod IPs) |
| **Uses iptables/IPVS** | Configures Linux networking under the hood |

### 3. Container Runtime

```text
Think of it as: The ACTUAL CONSTRUCTION EQUIPMENT

  kubelet (manager) says: "Build this container"
  Container Runtime (bulldozer): *actually builds and runs it*
```

| Runtime | Notes |
|---------|-------|
| **containerd** | Most common, lightweight, production standard |
| **CRI-O** | Alternative, built specifically for Kubernetes |
| ~~Docker~~ | Removed in K8s 1.24 (Docker images still work, the runtime was replaced) |

---

## How Everything Talks to Each Other

```text
  kubectl apply -f deployment.yaml
        â”‚
        â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  API Server  â”‚ â”€â”€â”€â†’ â”‚    etcd     â”‚   (1) Store desired state
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚  (2) Notify
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Controller   â”‚   (3) "Oh, 3 replicas needed, 0 exist. Create 3 Pods"
  â”‚  Manager      â”‚
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚  (4) New Pod objects created (in etcd, no node assigned yet)
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Scheduler    â”‚   (5) "Pod A â†’ Node 1, Pod B â†’ Node 2, Pod C â†’ Node 1"
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚  (6) Updates Pod objects with node assignments
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  kubelet      â”‚   (7) "I see I'm assigned Pod A. Let me pull the image
  â”‚  (on Node 1)  â”‚        and start the container."
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚  (8) Container starts running
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  kube-proxy   â”‚   (9) "New Pod is running. Let me update network rules
  â”‚  (on Node 1)  â”‚        so traffic can reach it."
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Declarative vs. Imperative â€” A Critical Concept

Kubernetes is **declarative** (not imperative). This is a fundamental shift in thinking:

```text
IMPERATIVE (Traditional â€” telling the system WHAT TO DO step by step):
  "Create a server. Install nginx. Open port 80. Start nginx. 
   If it crashes, SSH in and restart it."

DECLARATIVE (Kubernetes â€” telling the system WHAT YOU WANT):
  "I want 3 nginx pods running on port 80."
  
  Kubernetes figures out HOW to make it happen and KEEPS it that way.
```

| Approach | Command | Thinking Style |
|----------|---------|---------------|
| **Imperative** | `kubectl run nginx --image=nginx` | "Do this now" |
| **Declarative** | `kubectl apply -f nginx.yaml` | "Make reality match this file" |

**Always use declarative (YAML files)** in production. Why?
- YAML files can be version-controlled (Git)
- They're reviewable in pull requests
- They're repeatable and predictable
- They document what your cluster should look like

---

## Control Plane: Single vs. High Availability

```text
DEVELOPMENT (Single Control Plane â€” OK for learning):

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Control Planeâ”‚ â† Single point of failure!
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
  Node 1   Node 2


PRODUCTION (HA Control Plane â€” Required!):

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Control Planeâ”‚  â”‚ Control Planeâ”‚  â”‚ Control Planeâ”‚
  â”‚  (Primary)   â”‚  â”‚  (Standby)   â”‚  â”‚  (Standby)   â”‚
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                 â”‚                 â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                 â”‚
              â”Œâ”€â”€â”€â”´â”€â”€â”€â”        â”Œâ”€â”€â”€â”´â”€â”€â”€â”
              â”‚Node 1 â”‚        â”‚Node 2 â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”˜

  â€¢ 3 or 5 etcd instances (odd number for consensus)
  â€¢ Load balancer in front of API Servers
  â€¢ If one control plane dies â†’ others take over
```

---

## Cluster Types: Where Does K8s Run?

| Type | Where | Best For | Examples |
|------|-------|----------|---------|
| **Local** | Your laptop | Learning, development | Minikube, Kind, k3d, Docker Desktop |
| **Managed** | Cloud provider | Production (recommended) | EKS (AWS), GKE (Google), AKS (Azure) |
| **Self-managed** | Your own servers | Full control, compliance | kubeadm, Rancher, OpenShift |

### Why Managed Kubernetes is Almost Always Better for Production

```text
Self-managed:
  You handle: Control plane setup, etcd backups, upgrades, certificates,
              networking, security patches, monitoring, node provisioning...
  âŒ Takes a dedicated team

Managed (EKS/GKE/AKS):
  Cloud handles: Control plane, etcd, upgrades, certificates, HA
  You handle: Worker nodes, your apps, security policies
  âœ… Focus on your app, not infrastructure
```

---

## Namespaces â€” Organizing Your Cluster

```text
Think of it as: DEPARTMENTS in a company

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                  CLUSTER                         â”‚
  â”‚                                                 â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
  â”‚  â”‚  namespace:      â”‚  â”‚  namespace:           â”‚ â”‚
  â”‚  â”‚  development     â”‚  â”‚  production           â”‚ â”‚
  â”‚  â”‚                  â”‚  â”‚                       â”‚ â”‚
  â”‚  â”‚  - web app (v2)  â”‚  â”‚  - web app (v1)       â”‚ â”‚
  â”‚  â”‚  - test database â”‚  â”‚  - prod database      â”‚ â”‚
  â”‚  â”‚  - debug tools   â”‚  â”‚  - monitoring         â”‚ â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
  â”‚                                                 â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
  â”‚  â”‚  namespace:      â”‚  â”‚  namespace:           â”‚ â”‚
  â”‚  â”‚  kube-system     â”‚  â”‚  monitoring           â”‚ â”‚
  â”‚  â”‚  (K8s internals) â”‚  â”‚                       â”‚ â”‚
  â”‚  â”‚                  â”‚  â”‚  - prometheus          â”‚ â”‚
  â”‚  â”‚  - CoreDNS       â”‚  â”‚  - grafana             â”‚ â”‚
  â”‚  â”‚  - kube-proxy    â”‚  â”‚  - alertmanager        â”‚ â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Default namespaces:

| Namespace | Purpose |
|-----------|---------|
| `default` | Where your stuff goes if you don't specify |
| `kube-system` | Kubernetes internal components |
| `kube-public` | Publicly accessible data (rarely used) |
| `kube-node-lease` | Node heartbeat tracking |

```bash
# List namespaces
kubectl get namespaces

# Create a namespace
kubectl create namespace staging

# List pods in a specific namespace
kubectl get pods -n staging

# List pods across ALL namespaces
kubectl get pods --all-namespaces
```

---

## Test Your Understanding ğŸ§ª

1. **What are the two main parts of a Kubernetes cluster?**
2. **What happens if etcd data is lost?**
3. **What's the difference between the Scheduler and the Controller Manager?**
4. **Why should you use YAML files instead of `kubectl run` commands in production?**
5. **Name the three components that run on every Worker Node.**
6. **Explain the reconciliation loop in your own words.**

<details>
<summary>Click to see answers</summary>

1. Control Plane (brain â€” API Server, etcd, Scheduler, Controller Manager) and Worker Nodes (muscles â€” kubelet, kube-proxy, container runtime).

2. You lose ALL cluster state. K8s won't know about any Pods, Services, Deployments, or Secrets. This is catastrophic â€” always back up etcd.

3. **Scheduler** decides WHERE (which node) a Pod runs. **Controller Manager** watches if the desired state matches actual state and takes action (creates/deletes Pods, manages Deployments, etc.).

4. YAML files are version-controlled (Git), reviewable (PRs), repeatable, and document what your cluster should look like. Imperative commands are fire-and-forget â€” no audit trail.

5. kubelet, kube-proxy, and container runtime (containerd/CRI-O).

6. "Kubernetes constantly compares what you ASKED for (desired state) with what ACTUALLY exists (current state). If they don't match, it takes action to fix it. This loop runs forever."

</details>

---

## What's Next?

â¡ï¸ **[03 â€” Pods](./03-pods.md)** â€” The smallest unit you deploy in Kubernetes
